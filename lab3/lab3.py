# -*- coding: utf-8 -*-
"""lab3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_vcEEk3W8YwhLmX9_Uytir3kQIYi0Xpd

ZAD 1
"""

import os
import random
import zipfile

import numpy as np
from itertools import compress

from PIL import Image
import seaborn as sns
import matplotlib.pyplot as plt

import torch
import torch.utils.data
from torch import optim
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torchvision import datasets, transforms

!pip install grad-cam
from pytorch_grad_cam import GradCAM, GradCAMPlusPlus, XGradCAM, FullGrad
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
from pytorch_grad_cam.utils.image import show_cam_on_image

from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc, confusion_matrix
from sklearn.preprocessing import label_binarize

DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

RANDOM_SEED = 68
random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

flatten = lambda x: [item for sublist in x for item in sublist]

def set_history(classification_scenario: bool = False):
    history = {
        "train-batch-loss": [],
        "train-epoch-loss": [],
        "valid-batch-loss": [],
        "valid-epoch-loss": [],
    }
    if classification_scenario:
        acc_history = {
            "train-batch-acc": [],
            "train-epoch-acc": [],
            "valid-batch-acc": [],
            "valid-epoch-acc": [],
        }
        history.update(acc_history)
    return history

def download_cats_vs_dogs():
    !wget --no-check-certificate \
        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \
        -O /tmp/cats_and_dogs_filtered.zip

    local_zip = '/tmp/cats_and_dogs_filtered.zip'
    zip_ref = zipfile.ZipFile(local_zip, 'r')
    zip_ref.extractall('/content')
    zip_ref.close()

def load_cats_vs_dogs(input_size: int):
    train_dir = "/content/cats_and_dogs_filtered/train/"
    test_dir = "/content/cats_and_dogs_filtered/validation/"
    if not (os.path.exists(train_dir) and os.path.exists(test_dir)):
        download_cats_vs_dogs()

    norm_mean = [0.485, 0.456, 0.406]
    norm_std = [0.229, 0.224, 0.225]
    transformations = transforms.Compose([
        transforms.Resize(input_size),
        transforms.CenterCrop(input_size),
        transforms.ToTensor(),
        transforms.Normalize(mean=norm_mean, std=norm_std)
    ])
    denorm_fun = lambda x: x*torch.Tensor(norm_std)+torch.Tensor(norm_mean)

    train_data = torchvision.datasets.ImageFolder(root=train_dir, transform=transformations)
    trainloader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)
    test_data = torchvision.datasets.ImageFolder(root=test_dir, transform=transformations)
    testloader  = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)
    testloader_batch1  = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False, num_workers=NUM_WORKERS)
    classes = testloader.dataset.classes

    return trainloader, testloader, testloader_batch1, classes, transformations, denorm_fun

def load_cifar(type: str, input_size: int):
    norm_mean = [0.4914, 0.4822, 0.4465]
    norm_std = [0.2023, 0.1994, 0.2010]
    transformations = transforms.Compose([
        transforms.Resize(input_size),
        transforms.CenterCrop(input_size),
        transforms.ToTensor(),
        transforms.Normalize(mean=norm_mean, std=norm_std)
    ])
    denorm_fun = lambda x: x*torch.Tensor(norm_std)+torch.Tensor(norm_mean)

    if type == 'CIFAR10':
        trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                                download=True, transform=transformations)
        testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                               download=True, transform=transformations)
        sub_classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
        classes = (sub_classes, None)

    elif type == 'CIFAR100':
        trainset = torchvision.datasets.CIFAR100(root='./data', train=True,
                                                 download=True, transform=transformations)
        testset = torchvision.datasets.CIFAR100(root='./data', train=False,
                                                download=True, transform=transformations)
        sub_classes = ('beaver', 'dolphin', 'otter', 'seal', 'whale',
                       'aquarium fish', 'flatfish', 'ray', 'shark', 'trout',
                       'orchids', 'poppies', 'roses', 'sunflowers', 'tulips',
                       'bottles', 'bowls', 'cans', 'cups', 'plates',
                       'apples', 'mushrooms', 'oranges', 'pears', 'sweet peppers',
                       'clock', 'computer keyboard', 'lamp', 'telephone', 'television',
                       'bed', 'chair', 'couch', 'table', 'wardrobe',
                       'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach',
                       'bear', 'leopard', 'lion', 'tiger', 'wolf',
                       'bridge', 'castle', 'house', 'road', 'skyscraper',
                       'cloud', 'forest', 'mountain', 'plain', 'sea',
                       'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo',
                       'fox', 'porcupine', 'possum', 'raccoon', 'skunk',
                       'crab', 'lobster', 'snail', 'spider', 'worm',
                       'baby', 'boy', 'girl', 'man', 'woman',
                       'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle',
                       'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel',
                       'maple', 'oak', 'palm', 'pine', 'willow',
                       'bicycle', 'bus', 'motorcycle', 'pickup truck', 'train',
                       'lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor')
        super_classes = ('aquatic mammals', 'fish', 'flowers', 'food containers', 'fruit and vegetables',
                         'household electrical devices', 'household furniture', 'insects', 'large carnivores',
                         'large man-made outdoor things', 'large natural outdoor scenes', 'large omnivores and herbivores'
                         'medium-sized mammals', 'non-insect invertebrates', 'people', 'reptiles',
                         'small mammals', 'trees', 'vehicles 1', 'vehicles 2')
        classes = (sub_classes, super_classes)

    else:
        raise NotImplementedError()

    trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,
                                              shuffle=True, num_workers=NUM_WORKERS)
    testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,
                                             shuffle=False, num_workers=NUM_WORKERS)
    testloader_batch1 = torch.utils.data.DataLoader(testset, batch_size=1,
                                             shuffle=False, num_workers=NUM_WORKERS)

    return trainloader, testloader, testloader_batch1, classes, transformations, denorm_fun

def load_fashion_mnist():
    train_data = datasets.FashionMNIST('./FashionMNIST', train=True, download=True, transform=transforms.ToTensor())
    train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)

    test_data = datasets.FashionMNIST('./FashionMNIST', train=False, download=True, transform=transforms.ToTensor())
    test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)
    return train_loader, test_loader

class PretrainedNetwork(torch.nn.Module):
    def __init__(self, net_type: str, freezing_layer: int =-1):
        super(PretrainedNetwork, self).__init__()
        if net_type == 'efficientnet_b0':
            self.model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)
        else:
            self.model = torch.hub.load('pytorch/vision:v0.6.0', net_type, pretrained=True)
        self.freezing_layer = freezing_layer
        self.freeze_layers()
        self.transfer_model(net_type)


    def transfer_model(self, net_type: str):
        if net_type == 'alexnet':
            self.input_size = 224
            intermediate_features = 1500
            self.model.classifier[1] = nn.Linear(self.model.classifier[1].in_features, self.model.classifier[1].out_features)
            self.model.classifier[4] = nn.Linear(self.model.classifier[4].in_features, intermediate_features)
            self.model.classifier[6] = self.build_fc(intermediate_features)

        elif net_type == 'inception_v3':
            self.input_size = 299
            self.model.AuxLogits.fc = self.build_fc(self.model.AuxLogits.fc.in_features)
            self.model.fc = self.build_fc(self.model.fc.in_features)

        elif net_type in ['resnet18', 'resnet50', 'resnet101', 'resnext50_32x4d', 'shufflenet_v2_x1_0']:
            self.input_size = 224
            self.model.fc = self.build_fc(self.model.fc.in_features)

        elif net_type == 'densenet121':
            self.input_size = 224
            self.model.classifier = self.build_fc(self.model.classifier.in_features)

        elif net_type == 'efficientnet_b0':
            self.input_size = 256
            self.model.classifier.fc = self.build_fc(self.model.classifier.fc.in_features)

        else:
            raise Exception('No such model defined')


    def freeze_layers(self):
        if self.freezing_layer>=0:
            for param in self.model.parameters():
                param.requires_grad = False


    def build_fc(self, input_features: int):
        return nn.Linear(input_features, NUM_CLASSES)


    def forward(self, x):
        # self.backbone.aux_logit=False
        return self.model(x)


    def parameters_to_update(self):
        if self.freezing_layer>=0:
            params_to_update = []
            for name, param in self.model.named_parameters():
                if param.requires_grad == True:
                    params_to_update.append(param)
        else:
            params_to_update = self.model.parameters()
        return params_to_update


    def embedding(self, x):
        # https://discuss.pytorch.org/t/how-can-i-extract-intermediate-layer-output-from-loaded-cnn-model/77301/2
        pass

class EarlyStopping:
    """Early stops the training if validation loss doesn't improve after a given patience."""
    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):
        """
        Args:
            patience (int): How long to wait after last time validation loss improved.
                            Default: 7
            verbose (bool): If True, prints a message for each validation loss improvement.
                            Default: False
            delta (float): Minimum change in the monitored quantity to qualify as an improvement.
                            Default: 0
            path (str): Path for the checkpoint to be saved to.
                            Default: 'checkpoint.pt'
            trace_func (function): trace print function.
                            Default: print
        """
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.Inf
        self.delta = delta
        self.path = path
        self.trace_func = trace_func
    def __call__(self, val_loss, model):

        score = -val_loss

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        elif score < self.best_score + self.delta:
            self.counter += 1
            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0

    def save_checkpoint(self, val_loss, model):
        '''Saves model when validation loss decrease.'''
        if self.verbose:
            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')
        torch.save(model.state_dict(), self.path)
        self.val_loss_min = val_loss

def train_ilsvrc(model: torch.nn.Module, epoch: int):
    train_loss = train_acc = 0
    batch_loss = batch_acc = []

    model.train()
    print('='*25, 'EPOCH', epoch, '='*25)
    for batch_idx, (data, label) in enumerate(train_loader, 1):
        optimizer.zero_grad()
        data = data.to(DEVICE)
        label = label.to(DEVICE)

        if imagenet_backbone == 'Inceptionv3':
            model.aux_logits=True
            output, aux_output = model(data)
            loss1 = criterion(output, label)
            loss2 = criterion(aux_output, label)
            loss = loss1 + 0.4*loss2
        else:
            output = model(data)
            loss = criterion(output, label)
        loss.backward()
        cur_loss = loss.item()
        avg_batch_loss = cur_loss/len(data)
        batch_loss.append(avg_batch_loss)
        train_loss += cur_loss
        optimizer.step()

        _, pred = torch.max(output, 1)
        correct = np.squeeze(pred.eq(label.data.view_as(pred)))
        cur_acc = correct.sum().item()
        step_acc = cur_acc/len(data)
        batch_acc.append(step_acc)
        train_acc += cur_acc

        if batch_idx % LOG_INTERVAL == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}\tAcc: {:.6f}'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                100.*batch_idx / len(train_loader),
                avg_batch_loss, step_acc))

    avg_epoch_loss = train_loss / len(train_loader.dataset)
    epoch_acc = train_acc / len(train_loader.dataset)
    print('====> Trainset loss: {:.4f}\tAccuracy: {:.4f}'.format(
        avg_epoch_loss, epoch_acc
    ))
    HISTORY["train-batch-loss"].append(batch_loss)
    HISTORY["train-epoch-loss"].append(avg_epoch_loss)
    HISTORY["train-batch-acc"].append(batch_acc)
    HISTORY["train-epoch-acc"].append(epoch_acc)
    return  model

def test_ilsvrc(model: torch.nn.Module):
    test_loss = test_acc = 0.0
    batch_loss = batch_acc = []
    predictions = targets = []

    model.eval()
    if imagenet_backbone == 'Inceptionv3':
        model.aux_logits=False
    for data, label in test_loader:
        # assert len(label.data) == BATCH_SIZE
        data = data.to(DEVICE)
        label = label.to(DEVICE)
        output = model(data)

        loss = criterion(output, label)
        cur_loss = loss.item()
        avg_batch_loss = cur_loss/len(data)
        batch_loss.append(avg_batch_loss)
        test_loss += cur_loss

        _, pred = torch.max(output, 1)
        correct = np.squeeze(pred.eq(label.data.view_as(pred)))
        cur_acc = correct.sum().item()
        step_acc = cur_acc/len(data)
        batch_acc.append(step_acc)
        test_acc += cur_acc

        predictions.extend(list(pred.squeeze()))
        targets.extend(list(label.squeeze()))

    avg_epoch_loss = test_loss / len(test_loader.dataset)
    epoch_acc = test_acc / len(test_loader.dataset)
    print('====> Testset loss: {:.4f}\tAccuracy: {:.4f}'.format(avg_epoch_loss, epoch_acc))
    HISTORY["valid-batch-loss"].append(batch_loss)
    HISTORY["valid-epoch-loss"].append(avg_epoch_loss)
    HISTORY["valid-batch-acc"].append(batch_acc)
    HISTORY["valid-epoch-acc"].append(epoch_acc)
    return predictions, targets

def print_classification_report(labels, predicted, classes):
    print(classification_report(labels, predicted, target_names=classes))

def plot_confmat(labels, predicted, classes, title: str):
    conf_mat = confusion_matrix(labels, predicted)
    fig, ax = plt.subplots(figsize=(len(classes)*1.2, len(classes)*1.2))
    sns.heatmap(conf_mat, cmap='Blues', annot=True, linewidths=0.5, fmt='g', square=True, xticklabels=classes, yticklabels=classes)
    plt.title(title)
    plt.xlabel('Predicted label')
    plt.ylabel('True label')
    plt.show()

def plot_example_predictions(labels, predicted, confidence, images, num_samples_per_class: int, success: bool):
    fig, ax = plt.subplots(nrows=NUM_CLASSES, ncols=num_samples_per_class, figsize=(15/6*num_samples_per_class,3*NUM_CLASSES))
    for unique_class in range(NUM_CLASSES):
        if success:
            indices = [a and b for a, b in zip(np.array(labels) == unique_class, np.array(labels) == np.array(predicted))]
        else:
            indices = [a and b for a, b in zip(np.array(labels) == unique_class, np.array(labels) != np.array(predicted))]
        indices = list(compress(range(len(indices)), indices))
        num_samples = np.min([num_samples_per_class, len(indices)])
        idx_sample = random.sample(indices, num_samples)

        for idx, sample in enumerate(idx_sample):
            ax[unique_class][idx].imshow(denorm_fun(images[sample].permute(1,2,0)))
            ax[unique_class][idx].set_title('predicted={0}\ntrue={1}\nconfidence={2:.2f}%'.format(classes[predicted[sample]], classes[labels[sample]], 100*confidence[sample]))
        for idx in range(num_samples_per_class):
            ax[unique_class][idx].axis('off')
    plt.show()

def gather_test_results():
    test_summary = {
        'images': [],
        'labels': [],
        'logits': [],
        'proba': [],
        'predicted': [],
        'confidence': [],
    }

    with torch.no_grad():
        if imagenet_backbone == 'Inceptionv3':
            model.aux_logits=False
        for step, (img, y) in enumerate(test_loader_batch1):
            _predict = model(img.to(DEVICE))
            proba = F.softmax(_predict, dim=1)
            test_summary['images'].append(img.cpu().squeeze())
            test_summary['labels'].append(y.cpu().numpy()[0])
            test_summary['logits'].append(_predict.cpu().numpy()[0])
            test_summary['proba'].append(proba.cpu().numpy()[0])
            test_summary['predicted'].append(np.argmax(_predict.cpu().numpy()))
            test_summary['confidence'].append(np.max(proba.cpu().numpy()))

    return test_summary

def choose_target_layer(imagenet_backbone: str):
    if imagenet_backbone == 'AlexNet':
        target_layers = [model.model.features[6]]
    elif imagenet_backbone in ['ResNet18', 'ResNet50']:
        target_layers = [model.model.layer4[-1]]
    elif imagenet_backbone == 'ResNet101':
        target_layers = [model.model.layer4[-3]]
    elif imagenet_backbone == 'ResNeXt':
        target_layers = [model.model.layer4[-3]]
    elif imagenet_backbone == 'Inceptionv3':
        target_layers = [model.model.Mixed_7c[-1]]
    elif imagenet_backbone == 'ShuffleNetv2':
        target_layers = [model.model.conv5[-1]]
    elif imagenet_backbone == 'DenseNet':
        target_layers = [model.model.features.denseblock4]
    elif imagenet_backbone == 'EfficientNet_b0':
        target_layers = [model.model.features]
    else:
        raise NotImplementedError
    return target_layers

def predict_and_explain(filenames, transformations, imagenet_backbone):
    num_uploads = len(filenames)
    target_layers = choose_target_layer(imagenet_backbone)
    fig, ax = plt.subplots(NUM_CLASSES+1, num_uploads, figsize=(3*(num_uploads), 3*NUM_CLASSES))
    for idx, file in enumerate(filenames):
        img = Image.open(file)
        input_tensor = transformations(img).unsqueeze(dim=0).to(DEVICE)
        img = denorm_fun(input_tensor[0,:,:,:].cpu().permute(1,2,0))

        # model output
        with torch.no_grad():
            if imagenet_backbone == 'Inceptionv3':
                model.aux_logits=False
            prediction = model(input_tensor).cpu()
        predicted_label = np.argmax(prediction)
        confidence = F.softmax(prediction, dim=1).numpy().max()

        if num_uploads == 1:
            axs = ax[0]
        else:
            axs = ax[0][idx]
        axs.imshow(img)
        axs.set_title('predicted={0}\nconfidence={1:.2f}%'.format(classes[predicted_label], 100*confidence))
        axs.axis('off')

        # saliency map
        for jdx, label in enumerate(classes):
            cam = XGradCAM(model=model, target_layers=target_layers)
            cam_type = str(cam.__class__)[-10:-2]
            targets = [ClassifierOutputTarget(jdx)]
            grayscale_cam = cam(input_tensor=input_tensor, targets=targets)
            visualization = show_cam_on_image(np.array(img), grayscale_cam[0, :], use_rgb=True)

            if num_uploads == 1:
                axs = ax[jdx+1]
            else:
                axs = ax[jdx+1][idx]
            if jdx == 0 or cam_type != 'FullGrad':
                axs.imshow(visualization)
            axs.xaxis.set_ticklabels([])
            axs.yaxis.set_ticklabels([])
            if idx == 0 and cam_type != 'FullGrad':
                axs.set_ylabel(label + ' predictor')
            elif idx == 0 and cam_type == 'FullGrad':
                axs.set_ylabel('full grad explained')
            if jdx == 1 and cam_type == 'FullGrad':
                axs.axis('off')

class VAE(nn.Module):
    '''
    Variational AutoEncoder (VAE)
    https://github.com/pytorch/examples/blob/main/vae/main.py
    '''
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(IMAGE_SHAPE*IMAGE_SHAPE, 500)
        self.fc21 = nn.Linear(500, Z_DIM)  # fc21 for mean of Z
        self.fc22 = nn.Linear(500, Z_DIM)  # fc22 for log variance of Z
        self.fc3 = nn.Linear(Z_DIM, 500)
        self.fc4 = nn.Linear(500, IMAGE_SHAPE*IMAGE_SHAPE)

    def encode(self, x):
        h1 = F.relu(self.fc1(x))
        mu = self.fc21(h1)
        logvar = self.fc22(h1)
        return mu, logvar

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5*logvar)
        eps = torch.rand_like(std)
        return mu + eps*std

    def decode(self, z):
        h3 = F.relu(self.fc3(z))
        return torch.sigmoid(self.fc4(h3))

    def forward(self, x):
        x = x.view(-1, IMAGE_SHAPE*IMAGE_SHAPE)
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar

def vae_loss_function(recon_x, x, mu, logvar):
    BCE = F.binary_cross_entropy(recon_x, x.view(-1, IMAGE_SHAPE*IMAGE_SHAPE), reduction='sum')
    KLD = 0.5 * torch.sum(mu.pow(2) + logvar.exp() - logvar - 1)
    return BCE + KLD

def train_vae(model: torch.nn.Module, epoch: int):
    train_loss = 0
    batch_loss = []
    model.train()
    print('='*25, 'EPOCH', epoch, '='*25)
    for batch_idx, (data, _) in enumerate(train_loader):
        optimizer.zero_grad()
        data = data.to(DEVICE)
        reconstructed, mu, logvar = model(data)

        loss = vae_loss_function(reconstructed, data, mu, logvar)
        loss.backward()
        cur_loss = loss.item()
        avg_batch_loss = cur_loss/len(data)
        batch_loss.append(avg_batch_loss)
        train_loss += cur_loss
        optimizer.step()

        if batch_idx % LOG_INTERVAL == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                100.*batch_idx / len(train_loader),
                avg_batch_loss))

    avg_epoch_loss = train_loss / len(train_loader.dataset)
    print('====> Epoch: {} Average loss: {:.4f}'.format(
        epoch, avg_epoch_loss
    ))
    HISTORY["train-batch-loss"].append(batch_loss)
    HISTORY["train-epoch-loss"].append(avg_epoch_loss)
    return model

def test_vae(epoch):
    test_loss = 0
    batch_loss = []
    model.eval()
    with torch.no_grad():
        for batch_idx, (data, label) in enumerate(test_loader):
            data = data.to(DEVICE)
            reconstructed, mu, logvar = model(data)

            loss = vae_loss_function(reconstructed, data, mu, logvar)
            cur_loss = loss.item()
            avg_batch_loss = cur_loss/len(data)
            batch_loss.append(avg_batch_loss)
            test_loss += cur_loss

            # plot example reconstructions
            if batch_idx == 0:
                num_samples = min(BATCH_SIZE, PLOT_EXAMPLES)
                true = data[:num_samples].cpu()
                predicted = reconstructed.view(BATCH_SIZE, 1, IMAGE_SHAPE, IMAGE_SHAPE)[:num_samples].cpu()
                plot_reconstructions(true.permute(2,3,1,0), predicted.permute(2,3,1,0))

    avg_epoch_loss = test_loss / len(test_loader.dataset)
    print('====> Test set loss: {:.4f}'.format(avg_epoch_loss))
    HISTORY["valid-batch-loss"].append(batch_loss)
    HISTORY["valid-epoch-loss"].append(avg_epoch_loss)

def plot_reconstructions(true, predicted):
    print('====> Example predictions on validation dataset')
    fig, ax = plt.subplots(2, PLOT_EXAMPLES, figsize=(12,2))
    for i in range(PLOT_EXAMPLES):
        ax[0][i].imshow(np.repeat(true[:, :, :, i], 3, axis=2))
        ax[0][i].set_title('#{}'.format(i+1))
        ax[0][i].set_axis_off()
        ax[1][i].imshow(np.repeat(predicted[:, :, :, i], 3, axis=2))
        ax[1][i].set_axis_off()
    ax[0][0].set_ylabel('Validation example')
    ax[1][0].set_ylabel('Reconstructed')
    fig.tight_layout()
    plt.show()

BATCH_SIZE = 16
EPOCHS = 5

EARLY_STOPPING = True
PATIENCE = 2

LR_SCHEDULER = True
LEARNING_RATE = 1e-4

NUM_WORKERS = 2
LOG_INTERVAL = 20
HISTORY = set_history(classification_scenario=True)

#@title Dataset { display-mode: "form" }
DATASET = "cats-vs-dogs" #@param ["cats-vs-dogs", "CIFAR10", "CIFAR100"]
if DATASET == "cats-vs-dogs":
    NUM_CLASSES = 2
elif DATASET == "CIFAR10":
    NUM_CLASSES = 10
elif DATASET == "CIFAR100":
    NUM_CLASSES = 100
else:
    raise NotImplementedError

#@title Pretrained ImageNet architecture
imagenet_backbone = "AlexNet" #@param ["AlexNet", "ResNet18", "ResNet50", "ResNet101", "ResNeXt", "Inceptionv3", "ShuffleNetv2", "DenseNet", "EfficientNet_b0"]
torch_names = {
    'AlexNet': 'alexnet',
    'ResNet18': 'resnet18',
    'ResNet50': 'resnet50',
    'ResNet101': 'resnet101',
    'ResNeXt': 'resnext50_32x4d',
    'Inceptionv3': 'inception_v3',
    'ShuffleNetv2': 'shufflenet_v2_x1_0',
    'DenseNet': 'densenet121',
    'EfficientNet_b0': 'efficientnet_b0',
}

model = PretrainedNetwork(torch_names[imagenet_backbone])
model = model.to(DEVICE)

model

if DATASET == "cats-vs-dogs":
    train_loader, test_loader, test_loader_batch1, classes, transformations, denorm_fun = load_cats_vs_dogs(model.input_size)
    print('Trainset size:\t', len(train_loader.dataset.samples))
    print('Testset size:\t', len(test_loader.dataset.samples))
    print('Classes:\t', train_loader.dataset.classes)
elif DATASET[:5] == "CIFAR":
    train_loader, test_loader, test_loader_batch1, classes, transformations, denorm_fun = load_cifar(DATASET, model.input_size)
    classes, super_classes = classes
    print('Trainset size:\t', len(train_loader.dataset))
    print('Testset size:\t', len(test_loader.dataset))
    print('Classes:\t', train_loader.dataset.classes)
else:
    raise NotImplementedError

num_samples = 5
sample_batch = next(iter(train_loader))
fig, ax = plt.subplots(1, num_samples, figsize=(10,5))
for i in range(num_samples):
    ax[i].imshow(denorm_fun(sample_batch[0][i,:,:,:].permute(1,2,0)))
    ax[i].set_title(classes[int(sample_batch[1][i])])
    ax[i].axis('Off')

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters_to_update(), lr=LEARNING_RATE)

if LR_SCHEDULER:
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)

if EARLY_STOPPING:
    early_stopping = EarlyStopping(patience=PATIENCE, verbose=True)

for epoch in range(1, EPOCHS + 1):
    model = train_ilsvrc(model, epoch)
    predictions, targets = test_ilsvrc(model)

    if EARLY_STOPPING:
        early_stopping(HISTORY["valid-epoch-loss"][-1], model)
        if early_stopping.early_stop:
            print("Early stopping")
            break

    if LR_SCHEDULER:
        scheduler.step()

if EARLY_STOPPING:
    # load the last checkpoint with the best model
    model.load_state_dict(torch.load('checkpoint.pt'))

epochs = list(range(1,epoch+1))

fig, ax = plt.subplots(1,2, figsize=(14,5))
ax[0].plot(epochs, HISTORY["train-epoch-loss"], 'bo-')
ax[0].plot(epochs, HISTORY["valid-epoch-loss"], 'ro-')
ax[0].set_xticks(epochs)
ax[0].set_ylabel('loss')
ax[0].set_xlabel('epoch')
ax[0].legend(['train', 'valid'])
ax[0].grid(True)

ax[1].plot(epochs, HISTORY["train-epoch-acc"], 'bo-')
ax[1].plot(epochs, HISTORY["valid-epoch-acc"], 'ro-')
ax[1].set_xticks(epochs)
ax[1].set_ylabel('acc')
ax[1].set_xlabel('epoch')
ax[1].legend(['train', 'valid'])
ax[1].grid(True)

plt.show()

test_summary = gather_test_results()

print('='*15, ' CLASSIFICATION REPORT ', '='*15)
print_classification_report(test_summary['labels'], test_summary['predicted'], classes)

print('='*17, ' CONFUSION MATRIX ', '='*17)
plot_confmat(test_summary['labels'], test_summary['predicted'], classes, title='')

print('='*45, ' CORRECT PREDICTIONS ', '='*45)
plot_example_predictions(test_summary['labels'], test_summary['predicted'], test_summary['confidence'], test_summary['images'], 6, True)

print('='*45, ' FALSE PREDICTIONS ', '='*45)
plot_example_predictions(test_summary['labels'], test_summary['predicted'], test_summary['confidence'], test_summary['images'], 6, False)

"""ZAD 2"""

from google.colab import files
uploaded = files.upload()
filenames = list(uploaded.keys())

predict_and_explain(filenames, transformations, imagenet_backbone)
#roc_curve()
#auc()

model = PretrainedNetwork(torch_names[imagenet_backbone]).to(DEVICE)
predict_and_explain(filenames, transformations, imagenet_backbone)

"""ZAD 3"""

BATCH_SIZE = 128
EPOCHS = 5
LEARNING_RATE = 5e-3

IMAGE_SHAPE = 28
Z_DIM = 2

LOG_INTERVAL = 100
PLOT_EXAMPLES = 20
HISTORY = set_history()

"""#### **Dataset**"""

train_loader, test_loader = load_fashion_mnist()

"""#### **Trening modelu**"""

model = VAE().to(DEVICE)
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

model

for epoch in range(1, EPOCHS + 1):
    train_vae(model, epoch)
    test_vae(epoch)

# Plot loss
epochs = list(range(1,EPOCHS+1))
train_epochs_delim = [step*len(train_loader) for step in range(0,EPOCHS+1)]
valid_epochs_delim = [step*len(test_loader) for step in range(0,EPOCHS+1)]

plt.figure(figsize=(20,7))
plt.subplot(2, 1, 1)
plt.plot(flatten(HISTORY["train-batch-loss"]), 'b-')
plt.ylabel('train loss')
[plt.axvline(delim, color='k', linestyle='--') for delim in train_epochs_delim]
plt.grid(True)

plt.subplot(2, 1, 2)
plt.plot(flatten(HISTORY["valid-batch-loss"]), 'r-')
plt.xlabel('step')
plt.ylabel('valid loss')
[plt.axvline(delim, color='k', linestyle='--') for delim in valid_epochs_delim]
plt.grid(True)
plt.show()

plt.figure(figsize=(8,5))
plt.plot(epochs, HISTORY["train-epoch-loss"], 'bo-')
plt.plot(epochs, HISTORY["valid-epoch-loss"], 'ro-')
plt.xticks(epochs)
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'valid'])
plt.grid(True)
plt.show()

"""#### **Ewaluacja**"""

# Plot random samples from the latent space
GENERATE_SAMPLES = 20
sample = torch.randn(GENERATE_SAMPLES, Z_DIM).to(DEVICE)
sample = model.decode(sample).cpu().view(GENERATE_SAMPLES, 1, IMAGE_SHAPE, IMAGE_SHAPE)

fig, ax = plt.subplots(1,GENERATE_SAMPLES, figsize=(GENERATE_SAMPLES,5))
for i in range(GENERATE_SAMPLES):
    ax[i].imshow(sample[i].detach().numpy().squeeze(), cmap='Greys')
    ax[i].set_axis_off()

# Plot gridded view of the latent space
if Z_DIM == 2:
    GRID_SAMPLES = 20
    grid = torch.linspace(-2, 2, GRID_SAMPLES)
    mesh = torch.meshgrid(grid, grid, indexing='ij')
    mesh = np.hstack([torch.FloatTensor(mesh[0].reshape(-1,1)), torch.FloatTensor(mesh[1].reshape(-1,1))])
    mesh = torch.Tensor(mesh).to(DEVICE)
    x_grid = model.decode(mesh).cpu().view(GRID_SAMPLES*GRID_SAMPLES, 1, IMAGE_SHAPE, IMAGE_SHAPE)
    x_grid = x_grid.detach().numpy().reshape(GRID_SAMPLES, GRID_SAMPLES, IMAGE_SHAPE, IMAGE_SHAPE, 1)

    canvas = np.zeros((GRID_SAMPLES*IMAGE_SHAPE, GRID_SAMPLES*IMAGE_SHAPE))
    for xi in range(GRID_SAMPLES):
        for yi in range(GRID_SAMPLES):
            canvas[xi*IMAGE_SHAPE:xi*IMAGE_SHAPE+IMAGE_SHAPE, yi*IMAGE_SHAPE:yi*IMAGE_SHAPE+IMAGE_SHAPE] = x_grid[xi, yi,:,:,:].squeeze()

    fig, ax = plt.subplots(figsize=(10,10))
    ax.matshow(canvas, cmap='Greys')
    ax.axis('off')
    plt.show()